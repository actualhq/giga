#!/usr/bin/env python3

import os
import argparse
import logging
import json
import math

from giga.utils.logging import LOGGER
import pandas as pd

from giga.data.web.giga_api_client import GigaAPIClient
from giga.schemas.school import GigaSchoolTable
from giga.app.config import get_registered_countries
from giga.utils.globals import COUNTRY_DEFAULT_WORKSPACE
from giga.utils.logging import LOGGER


REGISTERED_COUNTRIES = get_registered_countries(COUNTRY_DEFAULT_WORKSPACE)


def main():
    parser = argparse.ArgumentParser()
    required = parser.add_argument_group("required arguments")
    required.add_argument("--workspace-directory", "-w", required=True)
    required.add_argument("--api-token", "-a", required=True)
    required.add_argument(
        "--country",
        "-c",
        choices=REGISTERED_COUNTRIES,
        help="Specifies the country of interest, your workspace will need to contain the data for that country",
        required=True,
    )
    args = parser.parse_args()

    LOGGER.info(f"Fetching up to date schools for country: {args.country.title()}")
    # export school data from project connect API
    client = GigaAPIClient(args.api_token)
    raw_schools = client.get_schools(args.country)

    # export supplemental data
    try:
        sup = pd.read_csv(
            os.path.join(args.workspace_directory, "schools_supplemental.csv")
        )
        assert all(
            k in sup.keys()
            for k in [
                "giga_id_school",
                "electricity",
                "fiber",
                "num_students",
                "coverage_type",
            ]
        ), "Supplemental data is missing required columns"
        sup = sup[
            ["giga_id_school", "electricity", "fiber", "num_students", "coverage_type"]
        ]
        sup = sup.rename(
            columns={
                "giga_id_school": "giga_id",
                "electricity": "has_electricity",
                "fiber": "has_fiber",
                "coverage_type": "cell_coverage_type",
            }
        )
    except FileNotFoundError:
        sup = pd.DataFrame(columns=["giga_id"])

    # transform raw school data
    assert (
        len(raw_schools) > 0
    ), "No schools found for country, perhaps there is an issue with the project connect API"
    table = GigaSchoolTable(schools=raw_schools)
    frame = table.to_data_frame()

    # update the values in base frame with supplemental data
    sup = sup.set_index("giga_id")
    frame = frame.set_index("giga_id")
    frame.update(sup)
    frame = frame.reset_index()
    frame["num_students"] = frame["num_students"].apply(
        lambda x: int(0 if x is None else x)
    )
    # make connectivity boolean
    frame["connected"] = frame["connectivity_status"].apply(
        lambda x: True if (x == "Good" or x == "Moderate") else False
    )
    # update names to match base schema
    frame = frame.rename(
        columns={
            "giga_id": "giga_id_school",
            "school_zone": "environment",
            "connectivity_status": "connectivity_speed_status",
        }
    )

    # write to csv in the desired workspace
    if not os.path.exists(args.workspace_directory):
        os.makedirs(args.workspace_directory)
    frame.to_csv(os.path.join(args.workspace_directory, "schools.csv"), index=0)


if __name__ == "__main__":
    main()
